{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Top 10 arrival airports in the world in 2013 (using the bookings file)\n",
    "\n",
    "Arrival airport is the column arr_port. It is the IATA code for the airport\n",
    "\n",
    "To get the total number of passengers for an airport, you can sum the \"pax\" column, grouping by arr_port.\n",
    "\n",
    "Note that there is negative pax. That corresponds to cancelations. So to get the total number of passengers that have actually booked, you should sum including the negatives (that will remove the canceled bookings).\n",
    "\n",
    "Print the top 10 arrival airports in the standard output, including the number of passengers.\n",
    "\n",
    "Bonus point: Get the name of the city or airport corresponding to that airport (programatically, we suggest to have a look at [neobase in Github](https://github.com/alexprengere/neobase))\n",
    "\n",
    "Bonus point: Solve this problem using pandas (instead of any other approach)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestion: follow the below plan of action:\n",
    "\n",
    "* Get familiar with the data\n",
    "* Select columns of interest\n",
    "* Decide what to do with NaNs\n",
    "\n",
    "* Make processing plan\n",
    "* Develop code that works with a sample\n",
    "\n",
    "* Adjust the code to work with Big data\n",
    "* Test big data approach on a sample\n",
    "\n",
    "* Run program with big data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get familiar with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we dont want to read the whole file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:\n",
    "\n",
    "* prepare the sample\n",
    "\n",
    "* read_csv with nrows option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Commands for obtaining data info:\n",
    "    b.shape  - object \n",
    "    b.info()\n",
    "\n",
    "    b.columns\n",
    "    b.columns.to_list()\n",
    "    list(b.columns)\n",
    "    \n",
    "    b.head() -function\n",
    "    b.sample()\n",
    "    \n",
    "    #pd.set_option('display.max_columns', 100)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    \n",
    "    b.describe()\n",
    "    b.describe(include='all')\n",
    "    df.dtypes\n",
    "    \n",
    "    b.isnull().sum()\n",
    "    non_null_counts = b.count()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Select the columns of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) What to do with NaN?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample everything might be ok, but we should prepare for NaN case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Make processing plan\n",
    "1) get only the bookings from 2013\n",
    "\n",
    "2) group by arr_port, sum\n",
    "\n",
    "3) sort \n",
    "\n",
    "4) get top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1) Get only the booking from 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2) group by arr_port, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Adjust the code to work with Big data\n",
    "\n",
    "\n",
    "Hint: check out https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need to put together the results from all the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Options:\n",
    "\n",
    "* df.append()\n",
    "\n",
    "* pd.concat()\n",
    "    \n",
    "    \n",
    "pd.concat handles several DataFrames in one go, while df.append creates a new DataFrame every time we call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airport Names\n",
    "\n",
    "Using [neobase](https://github.com/alexprengere/neobase), the successor to GeoBases. It's a referential data library that particularly focuses on airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Alternative\n",
    "\n",
    "Chunking with pandas DataFrames is a very general technique that can be applied to lots of datasets that don't fit in memory. It is useful to know because it's very widely applicable.\n",
    "\n",
    "However, very often small optimizations and tricks will allow us to get the job done, and they may be even quicker. \n",
    "\n",
    "In this case, the dataset is pretty close to fitting in memory, so just using the usecols argument to read_csv can get us there. It will only load the three relevant columns to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
